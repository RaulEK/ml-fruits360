{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31628 images belonging to 67 classes.\n",
      "Found 7885 images belonging to 67 classes.\n",
      "Found 16999 images belonging to 67 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB7\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "path = '../mergedData/'\n",
    "\n",
    "image_gen = ImageDataGenerator(validation_split=0.2)\n",
    "train_generator = image_gen.flow_from_directory(\n",
    "    path + \"Training\", target_size=(224, 224),batch_size=64, class_mode='categorical', subset='training')\n",
    "val_generator = image_gen.flow_from_directory(\n",
    "    path + \"Training\", target_size=(224, 224),batch_size=64, class_mode='categorical', subset='validation')\n",
    "\n",
    "test_generator = image_gen.flow_from_directory(\n",
    "    path + \"Test\", target_size=(224, 224),batch_size=64, class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple': 0, 'Apricot': 1, 'Avocado': 2, 'Banana': 3, 'Beetroot': 4, 'Blueberry': 5, 'Cactus': 6, 'Cantaloupe': 7, 'Carambula': 8, 'Cauliflower': 9, 'Cherry': 10, 'Chestnut': 11, 'Clementine': 12, 'Cocos': 13, 'Corn': 14, 'Cucumber': 15, 'Dates': 16, 'Eggplant': 17, 'Fig': 18, 'Ginger': 19, 'Granadilla': 20, 'Grape': 21, 'Grapefruit': 22, 'Guava': 23, 'Hazelnut': 24, 'Huckleberry': 25, 'Kaki': 26, 'Kiwi': 27, 'Kohlrabi': 28, 'Kumquats': 29, 'Lemon': 30, 'Limes': 31, 'Lychee': 32, 'Mandarine': 33, 'Mango': 34, 'Mangostan': 35, 'Maracuja': 36, 'Melon': 37, 'Mulberry': 38, 'Nectarine': 39, 'Nut': 40, 'Onion': 41, 'Orange': 42, 'Papaya': 43, 'Passion': 44, 'Peach': 45, 'Pear': 46, 'Pepino': 47, 'Pepper': 48, 'Physalis': 49, 'Pineapple': 50, 'Pitahaya': 51, 'Plum': 52, 'Pomegranate': 53, 'Pomelo': 54, 'Potato': 55, 'Quince': 56, 'Rambutan': 57, 'Raspberry': 58, 'Redcurrant': 59, 'Salak': 60, 'Strawberry': 61, 'Tamarillo': 62, 'Tangelo': 63, 'Tomato': 64, 'Walnut': 65, 'Watermelon': 66}\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)\n",
    "print(len(train_generator.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Convolution\n",
    "#    Non Linearity (ReLU)\n",
    "#    Pooling or Sub Sampling\n",
    "#    Classification (Fully Connected Layer)\n",
    "#    Peamised p√µhilayerid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(224, 224, 3))\n",
    "#x = img_augmentation(inputs)\n",
    "model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=inputs, classes=len(train_generator.class_indices))\n",
    "\n",
    "model.trainable = False\n",
    "x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "top_dropout_rate = 0.2\n",
    "x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "outputs = layers.Dense(len(train_generator.class_indices), activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "for layer in model.layers[-20:]:\n",
    "    if not isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_2 (Rescaling)         (None, 224, 224, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization_2 (Normalization) (None, 224, 224, 3)  7           rescaling_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 225, 225, 3)  0           normalization_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 112, 112, 32) 864         stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 112, 112, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 112, 112, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 112, 112, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 112, 112, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 112, 112, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 112, 112, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 112, 112, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 112, 112, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 112, 112, 96) 1536        block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 112, 112, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 112, 112, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 113, 113, 96) 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 56, 56, 96)   864         block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 56, 56, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 56, 56, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 56, 56, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 56, 56, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 56, 56, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 56, 56, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 56, 56, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 56, 56, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 56, 56, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 56, 56, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 56, 56, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 56, 56, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 56, 56, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 56, 56, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 56, 56, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 56, 56, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 56, 56, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 59, 59, 144)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 28, 28, 144)  3600        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 28, 28, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 28, 28, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 28, 28, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 28, 28, 40)   5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 28, 28, 40)   160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 28, 28, 240)  960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 28, 28, 240)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 28, 28, 240)  6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 28, 28, 240)  960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 28, 28, 240)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 28, 28, 240)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 28, 28, 40)   9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 28, 28, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 28, 28, 40)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 28, 28, 40)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 28, 28, 240)  960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 28, 28, 240)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 29, 29, 240)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 14, 14, 240)  2160        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 14, 14, 240)  960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 14, 14, 240)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 14, 14, 240)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 14, 14, 80)   19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 14, 14, 80)   320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 14, 14, 480)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 14, 14, 480)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 14, 14, 480)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 14, 14, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 14, 14, 80)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 14, 14, 80)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 14, 14, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 14, 14, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 14, 14, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 14, 14, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 14, 14, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 14, 14, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 14, 14, 480)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 14, 14, 480)  12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 14, 14, 480)  1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 14, 14, 480)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 14, 14, 480)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 14, 14, 112)  53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 14, 14, 112)  448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 14, 14, 672)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 14, 14, 672)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 14, 14, 672)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 14, 14, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 14, 14, 112)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 14, 14, 112)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 14, 14, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 14, 14, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 14, 14, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 14, 14, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 14, 14, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 14, 14, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 14, 14, 672)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 17, 17, 672)  0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 7, 7, 672)    16800       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 7, 7, 672)    2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 7, 7, 672)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 7, 7, 672)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 7, 7, 192)    129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 7, 7, 192)    768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 7, 7, 1152)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 7, 7, 1152)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 7, 7, 192)    768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 7, 7, 192)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 7, 7, 192)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 7, 7, 1152)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 7, 7, 1152)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 7, 7, 192)    768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 7, 7, 192)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 7, 7, 192)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 7, 7, 1152)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 7, 7, 1152)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 7, 7, 192)    768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 7, 7, 192)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 7, 7, 192)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 7, 7, 1152)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 7, 7, 1152)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 7, 7, 1152)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 7, 7, 320)    368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 7, 7, 320)    1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 7, 7, 1280)   409600      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 7, 7, 1280)   5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 7, 7, 1280)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1280)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1280)         5120        avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_dropout (Dropout)           (None, 1280)         0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pred (Dense)                    (None, 67)           85827       top_dropout[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 4,140,518\n",
      "Trainable params: 1,209,971\n",
      "Non-trainable params: 2,930,547\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seed = 1111\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "495/495 [==============================] - 1278s 3s/step - loss: 0.1022 - accuracy: 0.9753 - val_loss: 0.0383 - val_accuracy: 0.9915\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 1296s 3s/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0567 - val_accuracy: 0.9835\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 1286s 3s/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.1254 - val_accuracy: 0.9727\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 1277s 3s/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 0.0337 - val_accuracy: 0.9918\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 1276s 3s/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 0.1683 - val_accuracy: 0.9715\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 1277s 3s/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0602 - val_accuracy: 0.9848\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 1286s 3s/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0791 - val_accuracy: 0.9759\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 1281s 3s/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0333 - val_accuracy: 0.9905\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 1284s 3s/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0472 - val_accuracy: 0.9835\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 1315s 3s/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.0796 - val_accuracy: 0.9786\n",
      "266/266 [==============================] - 504s 2s/step - loss: 0.3475 - accuracy: 0.9498\n",
      "[0.3475292921066284, 0.9498205780982971]\n"
     ]
    }
   ],
   "source": [
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(train_generator, epochs=10, validation_data=val_generator, verbose=1)\n",
    "results = model.evaluate(test_generator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/karl/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/karl/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_model/effcient_net/assets\n",
      "WARNING:tensorflow:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_89461) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_69391) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_72354) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_86651) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_71086) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_70746) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_90054) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_92132) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_86284) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_73969) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_73228) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_93099) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_74109) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_74062) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_87343) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_69918) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_71574) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_69778) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_90520) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_73621) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_82552) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_72794) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_70166) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_74449) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_73181) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_73089) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_69530) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_74889) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_71527) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_70699) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_72401) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_69871) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_93791) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_75376) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_72841) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_93278) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_71434) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_74797) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_88769) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_71822) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_74496) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_70258) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_86830) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_70994) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_70606) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_91626) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_87710) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_87849) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_87204) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_74357) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_93238) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_75677) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_74936) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_91073) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_75769) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_91113) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_88442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_71133) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_functional_5_layer_call_and_return_conditional_losses_84200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_88263) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_89501) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_75816) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_87889) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_72262) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_93831) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_92685) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_63645) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_92725) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_91487) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_69483) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_93652) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_88948) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_73529) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_85818) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_73668) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_92172) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_76064) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_88908) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_75329) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_87383) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_91666) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_71961) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_85778) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_92546) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_94158) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_86324) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_90560) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_89875) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_71914) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_85639) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_70305) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_90934) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_86145) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_88402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_72702) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_75237) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_90381) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_90014) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_86790) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_91993) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_89322) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/effcient_net') \n",
    "new_model = tf.keras.models.load_model('saved_model/effcient_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "phone_img_gen = image_gen.flow_from_directory(\n",
    "    path + \"single_test/Apelsin\", target_size=(224, 224),batch_size=1, class_mode='categorical')\n",
    "results = new_model.predict(phone_img_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.66293959e-10 1.25643228e-11 4.76898480e-04 2.51912559e-13\n",
      " 3.17667490e-11 1.45356213e-10 1.40663543e-15 1.16138972e-05\n",
      " 2.85414886e-11 4.75402004e-07 1.53757530e-12 1.61124217e-12\n",
      " 1.51913898e-10 1.71752196e-12 6.15250201e-06 5.66523336e-13\n",
      " 3.70430409e-10 2.49647608e-10 5.71098963e-15 4.06797236e-13\n",
      " 1.52703151e-07 1.36397327e-09 1.35442484e-02 1.75758700e-13\n",
      " 1.06989111e-08 4.49648185e-14 1.14209667e-13 2.88677682e-09\n",
      " 5.89748583e-10 1.38971714e-08 1.45766077e-09 6.52044490e-02\n",
      " 1.51944041e-10 1.41361286e-14 1.47709319e-12 4.71300042e-14\n",
      " 1.35845016e-10 2.61920814e-08 9.06171351e-08 4.13260937e-09\n",
      " 1.31835942e-09 1.01138431e-13 9.07599866e-01 2.93141900e-10\n",
      " 7.49336926e-10 2.42749258e-11 1.97158487e-11 2.34298136e-11\n",
      " 3.52692209e-09 9.89386863e-14 1.05598585e-11 3.63810788e-13\n",
      " 1.77283146e-10 1.66460135e-14 1.31246569e-02 2.76121503e-09\n",
      " 3.51205257e-13 1.84875240e-10 4.16304803e-11 1.71489667e-12\n",
      " 5.71246141e-11 3.01718828e-05 3.13200403e-11 4.46095357e-14\n",
      " 3.85296905e-10 1.03333036e-06 3.97239668e-13]\n",
      "1.0113843e-13\n",
      "0.9999998\n",
      "---------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([42])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(results[0])\n",
    "print(results[0])\n",
    "print(results[0][41])\n",
    "print(np.sum(results[0]))\n",
    "print(\"---------\")\n",
    "#print(results[1])\n",
    "#print(results[1][41])\n",
    "#print(np.sum(results[1]))\n",
    "#print(\"---------\")\n",
    "#print(results[2])\n",
    "#print(results[2][3])\n",
    "#print(np.sum(results[2]))\n",
    "#print(\"---------\")\n",
    "results.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 593s 2s/step - loss: 0.3475 - accuracy: 0.9498\n",
      "[[1.88449165e-04 1.18725429e-05 5.91067590e-07 1.70532672e-08\n",
      "  4.95141030e-05 9.17277987e-08 9.31506174e-12 1.59771957e-07\n",
      "  6.23948324e-07 8.63845289e-01 4.26232930e-07 1.93095616e-07\n",
      "  1.39833367e-09 4.52617940e-07 4.27707797e-03 2.19787341e-10\n",
      "  7.47605282e-06 4.86568133e-05 8.80747628e-11 1.11467096e-04\n",
      "  5.37376865e-10 1.71523045e-08 2.86990660e-03 1.61471959e-07\n",
      "  4.78992579e-09 1.88330818e-09 7.82035325e-10 6.36480672e-06\n",
      "  7.92937651e-02 2.21266589e-07 1.62547522e-08 1.22585570e-05\n",
      "  2.46781383e-07 1.03239346e-08 1.94637551e-07 3.46365846e-06\n",
      "  6.46321574e-09 3.42942403e-05 8.42190548e-06 1.80292147e-06\n",
      "  6.07740822e-06 9.71949630e-05 4.10079374e-05 3.72073742e-07\n",
      "  1.57039995e-05 7.00282408e-06 3.18667475e-08 3.48474856e-07\n",
      "  4.47373837e-03 5.65296165e-09 1.37229566e-04 4.07888547e-05\n",
      "  4.25640121e-02 3.31341857e-06 5.27087877e-07 3.02061162e-05\n",
      "  1.14715315e-09 5.52620797e-04 2.09131365e-10 1.59737990e-09\n",
      "  4.17314094e-09 9.95782284e-06 1.94437444e-08 1.56425939e-09\n",
      "  3.26143927e-04 9.20102699e-04 4.64881360e-08]]\n"
     ]
    }
   ],
   "source": [
    "newresults = model.evaluate(test_generator)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
